{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7750032,"sourceType":"datasetVersion","datasetId":4530959},{"sourceId":7746478,"sourceType":"datasetVersion","datasetId":4528114},{"sourceId":7746427,"sourceType":"datasetVersion","datasetId":4528391},{"sourceId":13488,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":11170}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install openai","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AHjwSC5tamAE","outputId":"23b5c0cc-423c-4d4b-a672-efdb7f19033e","execution":{"iopub.status.busy":"2024-03-03T17:06:36.890505Z","iopub.execute_input":"2024-03-03T17:06:36.890896Z","iopub.status.idle":"2024-03-03T17:06:54.296503Z","shell.execute_reply.started":"2024-03-03T17:06:36.890866Z","shell.execute_reply":"2024-03-03T17:06:54.295044Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting openai\n  Downloading openai-1.13.3-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai) (4.2.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from openai) (0.27.0)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from openai) (2.5.3)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai) (1.3.0)\nRequirement already satisfied: tqdm>4 in /opt/conda/lib/python3.10/site-packages (from openai) (4.66.1)\nRequirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.10/site-packages (from openai) (4.9.0)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.6)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.4)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.14.6)\nDownloading openai-1.13.3-py3-none-any.whl (227 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.4/227.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: openai\nSuccessfully installed openai-1.13.3\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"id":"4dRLnY0kaplR","execution":{"iopub.status.busy":"2024-03-03T11:22:29.092908Z","iopub.execute_input":"2024-03-03T11:22:29.093371Z","iopub.status.idle":"2024-03-03T11:22:29.097650Z","shell.execute_reply.started":"2024-03-03T11:22:29.093303Z","shell.execute_reply":"2024-03-03T11:22:29.096868Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"pip install git+https://github.com/openai/whisper.git","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9q49LJ_UbZLd","outputId":"c667fa97-39c0-4230-a1c5-82ac9424b9df","execution":{"iopub.status.busy":"2024-03-03T17:06:54.300232Z","iopub.execute_input":"2024-03-03T17:06:54.300608Z","iopub.status.idle":"2024-03-03T17:07:34.644044Z","shell.execute_reply.started":"2024-03-03T17:06:54.300574Z","shell.execute_reply":"2024-03-03T17:07:34.642371Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/openai/whisper.git\n  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-o1j62iya\n  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-o1j62iya\n  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numba in /opt/conda/lib/python3.10/site-packages (from openai-whisper==20231117) (0.58.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from openai-whisper==20231117) (1.26.4)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from openai-whisper==20231117) (2.1.2+cpu)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from openai-whisper==20231117) (4.66.1)\nRequirement already satisfied: more-itertools in /opt/conda/lib/python3.10/site-packages (from openai-whisper==20231117) (10.2.0)\nCollecting tiktoken (from openai-whisper==20231117)\n  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\nCollecting triton<3,>=2.0.0 (from openai-whisper==20231117)\n  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.13.1)\nRequirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba->openai-whisper==20231117) (0.41.1)\nRequirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken->openai-whisper==20231117) (2023.12.25)\nRequirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (2024.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->openai-whisper==20231117) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\nDownloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: openai-whisper\n  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=802825 sha256=b74fee154695293e18daef8ad7d9ed3b0141dd1d09008d348608cbc62f5eeb72\n  Stored in directory: /tmp/pip-ephem-wheel-cache-b0solddi/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\nSuccessfully built openai-whisper\nInstalling collected packages: triton, tiktoken, openai-whisper\nSuccessfully installed openai-whisper-20231117 tiktoken-0.6.0 triton-2.2.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install vaderSentiment","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-8xR4k2S62JT","outputId":"3bfff26a-3f8f-4c3c-f476-357214451d7e","execution":{"iopub.status.busy":"2024-03-03T17:07:34.648648Z","iopub.execute_input":"2024-03-03T17:07:34.649045Z","iopub.status.idle":"2024-03-03T17:07:50.155824Z","shell.execute_reply.started":"2024-03-03T17:07:34.649012Z","shell.execute_reply":"2024-03-03T17:07:50.154501Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Collecting vaderSentiment\n  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata (572 bytes)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from vaderSentiment) (2.31.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->vaderSentiment) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->vaderSentiment) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->vaderSentiment) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->vaderSentiment) (2024.2.2)\nDownloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: vaderSentiment\nSuccessfully installed vaderSentiment-3.3.2\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport librosa\nimport librosa.display\nfrom IPython.display import Audio\nimport whisper\nimport numpy as np\nimport pandas as pd\nimport nltk\nimport keras\nimport pickle\nfrom keras.models import load_model\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nimport openai","metadata":{"execution":{"iopub.status.busy":"2024-03-03T17:07:54.487576Z","iopub.execute_input":"2024-03-03T17:07:54.488091Z","iopub.status.idle":"2024-03-03T17:08:18.082049Z","shell.execute_reply.started":"2024-03-03T17:07:54.488036Z","shell.execute_reply":"2024-03-03T17:08:18.080846Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"2024-03-03 17:08:03.906681: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-03 17:08:03.906863: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-03 17:08:04.102222: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/opt/conda/lib/python3.10/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n  warnings.warn(\"The twython library has not been installed. \"\n","output_type":"stream"}]},{"cell_type":"code","source":"import shutil\n\n# Copy the model file to the working directory\nshutil.copy(\"/kaggle/input/emotion_model/keras/emotion_model/1/best_model1.keras\", \"/kaggle/working/best_model1.keras\")\n\n# Load the model from the copied file\nmodel = load_model(\"/kaggle/working/best_model1.keras\")","metadata":{"execution":{"iopub.status.busy":"2024-03-03T17:08:40.834401Z","iopub.execute_input":"2024-03-03T17:08:40.834878Z","iopub.status.idle":"2024-03-03T17:08:43.767567Z","shell.execute_reply.started":"2024-03-03T17:08:40.834774Z","shell.execute_reply":"2024-03-03T17:08:43.766293Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"model_text = whisper.load_model(\"base\")\nsia = SentimentIntensityAnalyzer()\n\nmodel = load_model(\"/kaggle/working/best_model1.keras\")\n\nwith open('/kaggle/input/pickles/scaler2.pickle', 'rb') as f:\n    scaler2 = pickle.load(f)\n\nwith open('/kaggle/input/pickles/encoder2.pickle', 'rb') as f:\n    encoder2 = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2024-03-03T17:08:52.630089Z","iopub.execute_input":"2024-03-03T17:08:52.630543Z","iopub.status.idle":"2024-03-03T17:08:59.804316Z","shell.execute_reply.started":"2024-03-03T17:08:52.630509Z","shell.execute_reply":"2024-03-03T17:08:59.802812Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"100%|███████████████████████████████████████| 139M/139M [00:03<00:00, 40.2MiB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"def zcr(data, frame_length, hop_length):\n    zcr_values = librosa.feature.zero_crossing_rate(y=data, frame_length=frame_length, hop_length=hop_length)\n    return np.squeeze(zcr_values)\n\ndef rmse(data, frame_length=2048, hop_length=512):\n    rmse_values = librosa.feature.rms(y=data, frame_length=frame_length, hop_length=hop_length)\n    return np.squeeze(rmse_values)\n\ndef mfcc(data, sr, frame_length=2048, hop_length=512, flatten: bool = True):\n    mfcc_values = librosa.feature.mfcc(y=data, sr=sr, n_fft=frame_length, hop_length=hop_length)\n    return np.squeeze(mfcc_values.T) if not flatten else np.ravel(mfcc_values.T)\n\ndef extract_features(data, sr=22050, frame_length=2048, hop_length=512):\n    result = np.array([])\n\n    result = np.hstack((result,\n                        zcr(data, frame_length, hop_length),\n                        rmse(data, frame_length, hop_length),\n                        mfcc(data, sr, frame_length, hop_length)\n                       ))\n    return result\n\ndef get_predict_feat(path):\n    res=extract_features(path)\n    result=np.array(res)\n    desired_length = 2376\n    if len(result) < desired_length:\n        result = np.pad(result, (0, desired_length - len(result)), 'constant')\n    result=np.reshape(result,newshape=(1,2376))\n    i_result = scaler2.transform(result)\n    final_result=np.expand_dims(result, axis=2)\n    \n    return final_result\n\ndef prediction(path1):\n    res=get_predict_feat(path1)\n    predictions=model.predict(res)\n    y_pred = encoder2.inverse_transform(predictions)\n    return y_pred[0][0]\n\ndef split_audio(audio_path, duration=2.5):\n    y, sr = librosa.load(audio_path, sr=22050, offset = 0.6)\n    samples_per_interval = int(duration * sr)\n    audio_intervals = [y[i:i + samples_per_interval] for i in range(0, len(y), samples_per_interval)]\n    return audio_intervals\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-03T17:09:02.943076Z","iopub.execute_input":"2024-03-03T17:09:02.943465Z","iopub.status.idle":"2024-03-03T17:09:02.961175Z","shell.execute_reply.started":"2024-03-03T17:09:02.943436Z","shell.execute_reply":"2024-03-03T17:09:02.959600Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def get_scores(input_file):\n    predictions_arr = []\n    confidence_scores_arr = []\n    audio_path = input_file\n    intervals_array = split_audio(audio_path)\n    for i in intervals_array:\n        predicted_class = prediction(i)\n        predictions_arr.append(predicted_class)\n\n    for i in range(0, len(predictions_arr)):\n        if predictions_arr[i] == 'sad':\n            predictions_arr[i] = 0.5\n        if predictions_arr[i] == 'angry':\n            predictions_arr[i] = 1\n        if predictions_arr[i] == 'happy':\n            predictions_arr[i] = -1\n        if predictions_arr[i] == 'neutral':\n            predictions_arr[i] == -0.5\n\n    for i in range(0, len(predictions_arr) // 2):\n        predictions_arr[i] *= 0.8\n\n    speech_score = sum(predictions_arr) / (((len(predictions_arr) // 2) * 0.8) + len(predictions_arr) - (len(predictions_arr) // 2))   \n    \n    result2 = model_text.transcribe(input_file , fp16=False)\n    print(result2['text'])\n    text_score = sia.polarity_scores(result2['text'])['compound']\n    print(-1 * text_score)\n    final_score = (-0.35 * text_score) + (0.65 * speech_score)\n    return final_score\n    ","metadata":{"execution":{"iopub.status.busy":"2024-03-03T17:13:04.324259Z","iopub.execute_input":"2024-03-03T17:13:04.324731Z","iopub.status.idle":"2024-03-03T17:13:04.336639Z","shell.execute_reply.started":"2024-03-03T17:13:04.324696Z","shell.execute_reply":"2024-03-03T17:13:04.335411Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"sound_file = \"/kaggle/input/testaudio/WhatsApp Audio 2024-03-02 at 22.10.44_7c7cda28.wav\"\nfinal_score = get_scores(sound_file)\nprint(final_score)","metadata":{"execution":{"iopub.status.busy":"2024-03-03T17:13:06.309296Z","iopub.execute_input":"2024-03-03T17:13:06.309740Z","iopub.status.idle":"2024-03-03T17:13:12.174048Z","shell.execute_reply.started":"2024-03-03T17:13:06.309707Z","shell.execute_reply":"2024-03-03T17:13:12.172853Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n वो गोना सीतारम। यह परीगे बरीगा बरीगा मुवे ज व़ा दाजा जे जे तो वा देख़ा देख़ा देख़ा\n-0.0\n-0.2166666666666667\n","output_type":"stream"}]},{"cell_type":"code","source":"result2['text']","metadata":{"execution":{"iopub.status.busy":"2024-03-03T17:11:22.892256Z","iopub.execute_input":"2024-03-03T17:11:22.892682Z","iopub.status.idle":"2024-03-03T17:11:22.945645Z","shell.execute_reply.started":"2024-03-03T17:11:22.892652Z","shell.execute_reply":"2024-03-03T17:11:22.943995Z"},"trusted":true},"execution_count":16,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mresult2\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\n","\u001b[0;31mNameError\u001b[0m: name 'result2' is not defined"],"ename":"NameError","evalue":"name 'result2' is not defined","output_type":"error"}]}]}